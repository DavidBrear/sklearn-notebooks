{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mahotas as mh\n",
    "from mahotas.features import surf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import glob\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading 0 images\n",
      "Finished reading 100 images\n",
      "Finished reading 200 images\n",
      "Finished reading 300 images\n",
      "Finished reading 400 images\n",
      "Finished reading 500 images\n",
      "Finished reading 600 images\n",
      "Finished reading 700 images\n",
      "Finished reading 800 images\n",
      "Finished reading 900 images\n",
      "Finished reading 1000 images\n",
      "Finished reading 1100 images\n",
      "Finished reading 1200 images\n",
      "Finished reading 1300 images\n",
      "Finished reading 1400 images\n",
      "Finished reading 1500 images\n",
      "Finished reading 1600 images\n",
      "Finished reading 1700 images\n",
      "Finished reading 1800 images\n",
      "Finished reading 1900 images\n",
      "Finished reading 2000 images\n",
      "Finished reading 2100 images\n",
      "Finished reading 2200 images\n",
      "Finished reading 2300 images\n",
      "Finished reading 2400 images\n",
      "Finished reading 2500 images\n",
      "Finished reading 2600 images\n",
      "Finished reading 2700 images\n",
      "Finished reading 2800 images\n",
      "Finished reading 2900 images\n",
      "Finished reading 3000 images\n",
      "Finished reading 3100 images\n",
      "Finished reading 3200 images\n",
      "Finished reading 3300 images\n",
      "Finished reading 3400 images\n",
      "Finished reading 3500 images\n",
      "Finished reading 3600 images\n",
      "Finished reading 3700 images\n",
      "Finished reading 3800 images\n",
      "Finished reading 3900 images\n",
      "Finished reading 4000 images\n",
      "Finished reading 4100 images\n",
      "Finished reading 4200 images\n",
      "Finished reading 4300 images\n",
      "Finished reading 4400 images\n",
      "Finished reading 4500 images\n",
      "Finished reading 4600 images\n",
      "Finished reading 4700 images\n",
      "Finished reading 4800 images\n",
      "Finished reading 4900 images\n",
      "Finished reading 5000 images\n",
      "Finished reading 5100 images\n",
      "Finished reading 5200 images\n",
      "Finished reading 5300 images\n",
      "Finished reading 5400 images\n",
      "Finished reading 5500 images\n",
      "Finished reading 5600 images\n",
      "Finished reading 5700 images\n",
      "Finished reading 5800 images\n",
      "Finished reading 5900 images\n",
      "Finished reading 0 images\n",
      "Finished reading 100 images\n",
      "Finished reading 200 images\n",
      "Finished reading 300 images\n",
      "Finished reading 400 images\n",
      "Finished reading 500 images\n",
      "Finished reading 600 images\n",
      "Finished reading 700 images\n",
      "Finished reading 800 images\n",
      "Finished reading 900 images\n",
      "Finished reading 1000 images\n",
      "Finished reading 1100 images\n",
      "Finished reading 1200 images\n",
      "Finished reading 1300 images\n",
      "Finished reading 1400 images\n",
      "Finished reading 1500 images\n",
      "Finished reading 1600 images\n",
      "Finished reading 1700 images\n",
      "Finished reading 1800 images\n",
      "Finished reading 1900 images\n",
      "Finished reading 2000 images\n",
      "Finished reading 2100 images\n",
      "Finished reading 2200 images\n",
      "Finished reading 2300 images\n",
      "Finished reading 2400 images\n",
      "Finished reading 2500 images\n",
      "Finished reading 2600 images\n",
      "Finished reading 2700 images\n",
      "Finished reading 2800 images\n",
      "Finished reading 2900 images\n",
      "Finished reading 3000 images\n",
      "Finished reading 3100 images\n",
      "Finished reading 3200 images\n",
      "Finished reading 3300 images\n",
      "Finished reading 3400 images\n",
      "Finished reading 3500 images\n",
      "Finished reading 3600 images\n",
      "Finished reading 3700 images\n",
      "Finished reading 3800 images\n",
      "Finished reading 3900 images\n",
      "Finished reading 4000 images\n",
      "Finished reading 4100 images\n",
      "Finished reading 4200 images\n",
      "Finished reading 4300 images\n",
      "Finished reading 4400 images\n",
      "Finished reading 4500 images\n",
      "Finished reading 4600 images\n",
      "Finished reading 4700 images\n",
      "Finished reading 4800 images\n",
      "Finished reading 4900 images\n",
      "Finished reading 5000 images\n",
      "Finished reading 5100 images\n",
      "Finished reading 5200 images\n",
      "Finished reading 5300 images\n",
      "Finished reading 5400 images\n",
      "Finished reading 5500 images\n",
      "Finished reading 5600 images\n",
      "Finished reading 5700 images\n",
      "Finished reading 5800 images\n",
      "Finished reading 5900 images\n",
      "*Finished reading images*\n"
     ]
    }
   ],
   "source": [
    "all_instance_filenames = []\n",
    "all_instance_targets = []\n",
    "surf_features = []\n",
    "\n",
    "number_images = 6000\n",
    "\n",
    "data_path = './data/dog-v-cat/train/{}.*.jpg'\n",
    "\n",
    "for sp in ['cat', 'dog']:\n",
    "    path = data_path.format(sp)\n",
    "    count = 0\n",
    "    while count < number_images:\n",
    "        target = 1 if sp == 'cat' else 0\n",
    "        f = choice(glob.glob(path), replace=False)\n",
    "        image = mh.imread(f, as_grey=True)\n",
    "        surf_feature = surf.surf(image)[:, 5:]\n",
    "        if len(surf_feature) > 0:\n",
    "            if count % 100 == 0:\n",
    "                print 'Finished reading {} images'.format(count)\n",
    "            surf_features.append(surf_feature)\n",
    "            all_instance_targets.append(target)\n",
    "            count += 1\n",
    "    \n",
    "print '*Finished reading images*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_len = int(len(surf_features) * .60)\n",
    "X_train_surf_features = np.concatenate(surf_features[:train_len])\n",
    "X_test_surf_features = np.concatenate(surf_features[train_len:])\n",
    "y_train = all_instance_targets[:train_len]\n",
    "y_test = all_instance_targets[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering 4508548 features\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 300\n",
    "print 'Clustering', len(X_train_surf_features), 'features'\n",
    "estimator = MiniBatchKMeans(n_clusters=n_clusters)\n",
    "estimator.fit_transform(X_train_surf_features)\n",
    "\n",
    "# find the cluster associated with each of the extracted SURF descriptors and count.\n",
    "X_train = []\n",
    "counter = 0\n",
    "\n",
    "for instance in surf_features[:train_len]:\n",
    "    clusters = estimator.predict(instance)\n",
    "    features = np.bincount(clusters)\n",
    "    if len(features) < n_clusters:\n",
    "        features = np.append(features, np.zeros((1, n_clusters - len(features))))\n",
    "    X_train.append(features)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "\n",
    "for instance in surf_features[train_len:]:\n",
    "    clusters = estimator.predict(instance)\n",
    "    features = np.bincount(clusters)\n",
    "    if len(features) < n_clusters:\n",
    "        features = np.append(features, np.zeros((1, n_clusters - len(features))))\n",
    "    X_test.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.26      0.42      4800\n",
      "          1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.26      0.42      4800\n",
      "\n",
      "Precision: 0\n",
      "Recall: 0\n",
      "Accuracy: 0.26375\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.001, penalty='l2')\n",
    "clf.fit_transform(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "print classification_report(y_test, predictions)\n",
    "print 'Precision:', precision_score(y_test, predictions)\n",
    "print 'Recall:', recall_score(y_test, predictions)\n",
    "print 'Accuracy:', accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
